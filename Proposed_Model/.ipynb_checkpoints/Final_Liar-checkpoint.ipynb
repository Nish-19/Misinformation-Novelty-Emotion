{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For unpickling files\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\deep-learning-pytorch\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n",
      "E:\\Anaconda3\\envs\\deep-learning-pytorch\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Import the main dataset\n",
    "train_df = pd.read_table('../LIAR_PLUS_Dataset/liar_train.tsv')\n",
    "test_df = pd.read_table('../LIAR_PLUS_Dataset/liar_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely-true</th>\n",
       "      <th>false</th>\n",
       "      <th>half-true</th>\n",
       "      <th>mostly-true</th>\n",
       "      <th>pants-fire</th>\n",
       "      <th>venue</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>That's a premise that he fails to back up. Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>1</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "      <td>Surovell said the decline of coal \"started whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>1</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Obama said he would have voted against the ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>0</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "      <td>The release may have a point that Mikulskis co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>1</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "      <td>Crist said that the economic \"turnaround start...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  label                                          statement  \\\n",
       "0   2635.json      0  Says the Annies List political group supports ...   \n",
       "1  10540.json      1  When did the decline of coal start? It started...   \n",
       "2    324.json      1  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json      0  Health care reform legislation is likely to ma...   \n",
       "4   9028.json      1  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              subject         speaker                   job  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      state       party  barely-true  false  half-true  mostly-true  \\\n",
       "0     Texas  republican          0.0    1.0        0.0          0.0   \n",
       "1  Virginia    democrat          0.0    0.0        1.0          1.0   \n",
       "2  Illinois    democrat         70.0   71.0      160.0        163.0   \n",
       "3       NaN        none          7.0   19.0        3.0          5.0   \n",
       "4   Florida    democrat         15.0    9.0       20.0         19.0   \n",
       "\n",
       "   pants-fire                venue  \\\n",
       "0         0.0             a mailer   \n",
       "1         0.0      a floor speech.   \n",
       "2         9.0               Denver   \n",
       "3        44.0       a news release   \n",
       "4         2.0  an interview on CNN   \n",
       "\n",
       "                                       justification  \n",
       "0  That's a premise that he fails to back up. Ann...  \n",
       "1  Surovell said the decline of coal \"started whe...  \n",
       "2  Obama said he would have voted against the ame...  \n",
       "3  The release may have a point that Mikulskis co...  \n",
       "4  Crist said that the economic \"turnaround start...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()\n",
    "# 0 - False (pants fire, false, barely true)\n",
    "# 1 - True (true, mostly true, half-true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the novelty results\n",
    "train_pre_nv = pd.read_csv('Liar_Data/train_liar_0_3_combined.csv')\n",
    "test_pre_nv = pd.read_csv('Liar_Data/test_liar_0_3_combined.csv')\n",
    "train_pre_nv.columns = ['id', 'nv_label']\n",
    "test_pre_nv.columns = ['id', 'nv_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape is (10156, 200)\n",
      "Test shape is (1258, 200)\n"
     ]
    }
   ],
   "source": [
    "# Import novlety features\n",
    "train_novelty_feature = np.load('Liar_Data/train_liar_0_3_combine.npy')\n",
    "test_novelty_feature = np.load('Liar_Data/test_liar_0_3_combine.npy')\n",
    "# Examining the shape\n",
    "print('Train shape is', train_novelty_feature.shape)\n",
    "print('Test shape is', test_novelty_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the emotion results\n",
    "train_em = pd.read_csv('Liar_Data/liar_em_train_pre.tsv_k_numb_predictions_bin.csv', header = None)\n",
    "test_em = pd.read_csv('Liar_Data/liar_em_test_pre.tsv_k_numb_predictions_bin.csv', header = None)\n",
    "train_em.columns = ['id', 'em_label']\n",
    "test_em.columns = ['id', 'em_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the emotion features\n",
    "train_emotion_feature = unpickle('Liar_Data/liar_em_train_pre.tsv_k_bin.pickle')\n",
    "test_emotion_feature = unpickle('Liar_Data/liar_em_test_pre.tsv_k_bin.pickle')\n",
    "train_emotion_feature = np.stack(list(train_emotion_feature.values()))\n",
    "test_emotion_feature = np.stack(list(test_emotion_feature.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre-trained Glove embeddings\n",
    "embeddings_dict = {}\n",
    "with open(\"../resource/glove.6B.200d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embeddings_dict.keys(), key=lambda word: spatial.distance.euclidean(embeddings_dict[word], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.45048   -0.1449     0.069873  -0.2611     0.51599    0.2649\n",
      " -0.37062   -0.4043    -0.047766  -0.85103    0.15076   -0.3983\n",
      " -0.30388    0.13779    0.31623   -0.27125    0.45444    0.93036\n",
      "  0.37158   -0.13067    0.016844   2.2395     0.21558   -0.97138\n",
      " -0.15899    0.5531    -0.045112  -0.76692    0.0094216 -0.12936\n",
      " -0.21059   -0.11888    0.1508    -0.2525    -0.22782   -0.53595\n",
      " -0.40099   -0.58793    0.059262  -0.64623   -0.20917   -0.03534\n",
      " -0.034241  -0.08936   -0.16375    0.36763    0.82737   -0.10209\n",
      "  0.19804    0.4031    -0.36257   -0.072119   0.2679    -0.20291\n",
      "  0.10427    0.24153   -0.06382    0.4669    -0.12288    0.11546\n",
      " -0.11928    0.12932   -0.8338    -0.82749    0.014886  -0.57084\n",
      " -0.58857   -0.089826   0.39842    0.022715   0.54963   -0.30594\n",
      "  0.058506   0.33867    0.17773    0.30477   -0.13231    0.1711\n",
      " -0.26207   -0.20595    0.58286   -0.090458   0.026476   0.090705\n",
      "  0.20869   -0.22999   -0.51844   -0.82133    0.81661   -0.63622\n",
      "  0.10171    1.0201     0.3413     0.26636   -0.18423    0.061951\n",
      " -0.40571   -0.090038  -0.41384   -0.20045   -0.19265    0.22574\n",
      "  0.36075    0.22961    0.17827   -0.46498   -0.12471    0.28899\n",
      " -0.62006   -0.065422  -0.39506   -0.2934    -0.27075   -0.12682\n",
      " -0.68685   -0.092482  -0.11464   -0.25478   -0.029841  -0.27236\n",
      " -0.23404   -0.084875  -0.25363   -0.23576   -0.088948  -0.39006\n",
      "  0.52574    0.27163    0.21287   -0.59627   -0.07769   -0.10208\n",
      "  0.48794    0.18492    0.42157   -0.12221   -0.13376    0.03495\n",
      " -0.24528    0.11253   -0.44813    0.22358    0.36009   -0.52455\n",
      "  0.95692   -0.1516     0.25071   -0.13371   -0.21225   -0.24028\n",
      " -0.0052063  0.23967    0.33641   -0.35559    0.32381    0.015276\n",
      " -0.72171    0.15128    0.075665   0.10067    0.80637   -0.1628\n",
      " -0.34519   -0.20409    0.044463   0.39453   -0.6072    -0.69917\n",
      " -0.0069373  0.65796   -0.068019   0.32129    0.057593  -0.37796\n",
      " -0.15254   -0.060348   0.032573  -0.073871  -0.4728     0.40693\n",
      "  0.65814   -0.20265    0.35995   -0.34156   -0.069076  -0.16736\n",
      "  0.27587   -0.32745    0.15163    0.4556    -0.083554   0.40252\n",
      "  0.041925  -0.41251    0.43337   -0.76944   -0.17903    0.0067027\n",
      " -0.084438   0.37511  ]\n",
      "['originally', 'latter', 'addition', 'same', 'feature']\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_dict[\"original\"])\n",
    "print(find_closest_embeddings(embeddings_dict[\"original\"])[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing for further use\n",
    "novel = embeddings_dict[\"original\"]\n",
    "duplicate = embeddings_dict[\"duplicate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train bias (10156, 200)\n",
      "Test bias (1258, 200)\n"
     ]
    }
   ],
   "source": [
    "# Adding novelty bias\n",
    "true_train_labels = train_df['label'].tolist()\n",
    "true_test_labels = test_df['label'].tolist()\n",
    "train_bias = []\n",
    "test_bias = []\n",
    "zero_vector = np.zeros((200,))\n",
    "for i, row in train_pre_nv.iterrows():\n",
    "    if row['nv_label'] == 0 and true_train_labels[i] == 0:\n",
    "        train_bias.append(novel)\n",
    "    elif row['nv_label'] == 1 and true_train_labels[i] == 1:\n",
    "        train_bias.append(duplicate)\n",
    "    else:\n",
    "        train_bias.append(zero_vector)\n",
    "for i, row in test_pre_nv.iterrows():\n",
    "    if row['nv_label'] == 0 and true_test_labels[i] == 0:\n",
    "        test_bias.append(novel)\n",
    "    elif row['nv_label'] == 1 and true_test_labels[i] == 1:\n",
    "        test_bias.append(duplicate)\n",
    "    else:\n",
    "        test_bias.append(zero_vector)\n",
    "train_bias_nv = np.stack(train_bias)\n",
    "test_bias_nv = np.stack(test_bias)\n",
    "print('Train bias', train_bias_nv.shape)\n",
    "print('Test bias', test_bias_nv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True emotion (200,)\n",
      "Fake emotion (200,)\n"
     ]
    }
   ],
   "source": [
    "# Emotion Bias vectors\n",
    "emotion_true = embeddings_dict['anticipation']+embeddings_dict['sadness']+embeddings_dict['joy']+embeddings_dict['trust']\n",
    "emotion_false = embeddings_dict['anger']+embeddings_dict['fear']+embeddings_dict['disgust']+embeddings_dict['surprise']\n",
    "print('True emotion', emotion_true.shape)\n",
    "print('Fake emotion', emotion_false.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train bias (10156, 200)\n",
      "Test bias (1258, 200)\n"
     ]
    }
   ],
   "source": [
    "# Emotion Bias\n",
    "true_train_labels = train_df['label'].tolist()\n",
    "true_test_labels = test_df['label'].tolist()\n",
    "train_bias = []\n",
    "test_bias = []\n",
    "zero_vector = np.zeros((200,))\n",
    "for i, row in train_em.iterrows():\n",
    "    if row['em_label'] == 0 and true_train_labels[i] == 1:\n",
    "        train_bias.append(emotion_true)\n",
    "    elif row['em_label'] == 1 and true_train_labels[i] == 0:\n",
    "        train_bias.append(emotion_false)\n",
    "    else:\n",
    "        train_bias.append(zero_vector)\n",
    "for i, row in test_em.iterrows():\n",
    "    if row['em_label'] == 0 and true_test_labels[i] == 1:\n",
    "        test_bias.append(emotion_true)\n",
    "    elif row['em_label'] == 1 and true_test_labels[i] == 0:\n",
    "        test_bias.append(emotion_false)\n",
    "    else:\n",
    "        test_bias.append(zero_vector)\n",
    "train_bias_em = np.stack(train_bias)\n",
    "test_bias_em = np.stack(test_bias)\n",
    "print('Train bias', train_bias_em.shape)\n",
    "print('Test bias', test_bias_em.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_bias (10156, 200)\n",
      "Shape of test_bias (1258, 200)\n"
     ]
    }
   ],
   "source": [
    "# Combined bias\n",
    "train_bias = np.add(train_bias_nv, train_bias_em)\n",
    "test_bias = np.add(test_bias_nv, test_bias_em)\n",
    "print('Shape of train_bias', train_bias.shape)\n",
    "print('Shape of test_bias', test_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape is (10156, 200)\n",
      "Test shape is (1258, 200)\n"
     ]
    }
   ],
   "source": [
    "# Performing PCA on emotion features 768 -> 200\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=200)\n",
    "train_emotion_feature = pca.fit_transform(train_emotion_feature)\n",
    "test_emotion_feature = pca.transform(test_emotion_feature)\n",
    "print('Train shape is', train_emotion_feature.shape)\n",
    "print('Test shape is', test_emotion_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Master Features\n",
    "train_liar_features = np.add(train_novelty_feature, train_emotion_feature, train_bias)\n",
    "test_liar_features = np.add(test_novelty_feature, test_emotion_feature, test_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a LR model\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_liar = linear_model.LogisticRegression(max_iter = 5000)\n",
    "lr_liar.fit(train_liar_features, train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model is: 78.13990461049285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.68      0.93      0.79       549\n",
      "        true       0.93      0.66      0.77       709\n",
      "\n",
      "    accuracy                           0.78      1258\n",
      "   macro avg       0.81      0.80      0.78      1258\n",
      "weighted avg       0.82      0.78      0.78      1258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Infering on the test set\n",
    "y_pred = lr_liar.predict(test_liar_features)\n",
    "print(\"Accuracy of Logistic Regression model is:\",\n",
    "metrics.accuracy_score(test_df['label'], y_pred)*100)\n",
    "print(classification_report(test_df['label'], y_pred, target_names = ['false', 'true']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
